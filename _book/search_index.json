[
["index.html", "Understanding Web Data in R, and Building Clients Welcome", " Understanding Web Data in R, and Building Clients Scott Chamberlain Welcome This is the website for the book “Understanding Web Data in R, and Building Clients”. This work is licensed under the Creative Commons Attribution 4.0 International License "],
["introduction.html", "1 Introduction 1.1 What you will learn 1.2 Prerequisites 1.3 Acknowledgements 1.4 Colophon", " 1 Introduction R is a powerful language for working with data. There is an immense amount of data on the internet. This book goes over the individual parts of working with data on the web, and teaches you how to make packages to get data on the web. 1.1 What you will learn There are many components to working with data on the web. This book won’t be the most detailed in any of them, but will lay a foundation for doing each component well. You’ll learn about File Transfer Protocl (FTP), and how to work with it in R. Many government organizations provide data this way. It’s a great method for large data. Much of the book will cover working with web Application Programming Interfaces (APIs). Public APIs are all over the place now: there’s on for IMDB, for Star Wars, for many US government departments, and a lot more. Finally, we’ll cover how to write R packages to work with data on the web, whether the data is from FTP, scraped from website, or through a web API. 1.2 Prerequisites To run the code in this book, you will need to install both R and the RStudio IDE, an application that makes R easier to use. Both are open source, free and easy to install: Download and install R, https://www.r-project.org/alt-home/. Download and install RStudio, http://www.rstudio.com/download. Install needed packages (see below). 1.2.1 R packages pkgs &lt;- c( &quot;jsonlite&quot;, &quot;knitr&quot;, &quot;httr&quot; ) install.packages(pkgs) You’ll also need to install some R packages. An R package is a collection of functions, data, and documentation that extends the capabilities of base R. Using packages is key to the successful use of R. To install all the packages used in this book open RStudio and run: R will download the packages from CRAN and install them in your system library. If you have problems installing, make sure that you are connected to the internet, and that you haven’t blocked https://cran.rstudio.com in your firewall or proxy. You will not be able to use the functions, objects, and help files in a package until you load it with library(). After you have downloaded the packages, you can load any of the packages into your current R session with the library() command, e.g. library(httr) You will need to reload the package every time you start a new R session. 1.3 Acknowledgements xxx 1.4 Colophon This book was built with: devtools::session_info(pkgs) #&gt; Session info -------------------------------------------------------------- #&gt; setting value #&gt; version R version 3.3.0 Patched (2016-05-09 r70593) #&gt; system x86_64, darwin13.4.0 #&gt; ui X11 #&gt; language (EN) #&gt; collate en_US.UTF-8 #&gt; tz America/Los_Angeles #&gt; date 2016-06-17 #&gt; Packages ------------------------------------------------------------------ #&gt; package * version date source #&gt; curl 0.9.7 2016-04-10 CRAN (R 3.3.0) #&gt; digest 0.6.9 2016-01-08 CRAN (R 3.3.0) #&gt; evaluate 0.9 2016-04-29 CRAN (R 3.3.0) #&gt; formatR 1.4 2016-05-09 CRAN (R 3.3.0) #&gt; highr 0.6 2016-05-09 CRAN (R 3.3.0) #&gt; httr 1.2.0 2016-06-15 CRAN (R 3.3.0) #&gt; jsonlite 0.9.22 2016-06-15 CRAN (R 3.3.0) #&gt; knitr 1.13.1 2016-06-17 Github (yihui/knitr@ce40cbf) #&gt; magrittr 1.5 2014-11-22 CRAN (R 3.3.0) #&gt; markdown 0.7.7 2015-04-22 CRAN (R 3.3.0) #&gt; mime 0.4 2015-09-03 CRAN (R 3.3.0) #&gt; openssl 0.9.4 2016-05-25 CRAN (R 3.3.0) #&gt; R6 2.1.2 2016-01-26 CRAN (R 3.3.0) #&gt; stringi 1.1.1 2016-05-27 CRAN (R 3.3.0) #&gt; stringr 1.0.0 2015-04-30 CRAN (R 3.3.0) #&gt; yaml 2.1.13 2014-06-12 CRAN (R 3.3.0) "],
["data-types.html", "2 Data Types 2.1 JSON 2.2 XML 2.3 HTML 2.4 Files", " 2 Data Types There are a lot of different types of data from the web that you may work with - I’ll go over the major ones as it’s important to be familiar with the data you’ll be working with in this book. 2.1 JSON JSON (Javascript Object Notation) is becoming the most common data format on the web. Compared to XML (described below), it is simpler, and easier for humans to read. However, JSON does lose some specificity and metadata that XML is so good at. There is a variant of JSON called JSON-LD, for JSON Linked Data, that allows context to be included with a JSON document, e.g., linking to schema. The most basic valid JSON document is {}, but of course it carries little value. A basic JSON blob with information looks like: { &quot;hello&quot;: &quot;world&quot; } Another example: { &quot;foo&quot;: { &quot;bar&quot;: &quot;Hello World!&quot; } } JSON http://www.json.org/ is built on two structures: A collection of name-value pairs, where the name is a string and the value can be a variety of objects. An ordered list of values. In most languages, this is realized as an array, vector, list, or sequence. JSON data structures: object: An unordered set of name/value pairs. Begins with {, and ends with }. Each name is followed by :, and the name/value pairs are separated by ,. array: An ordered collection of values. Begins with [, and ends with ]. Values are separated by ,. value: A string in double quotes, a number, true or false, null, an object, or an array. Can be nested. string: A sequence of zero or more Unicode characters, wrapped in double quotes, using backslash escapes. number: A number. There are likely parsers in all programming languages, making it super easy to work with. Most web APIs provide JSON as the default data format, or at least provide it as an option. In R, the best way to work with JSON is with the jsonlite package, made by Jeroen Ooms. It is a modern JSON processor, and importantly converts JSON data structures described above to equivalent R data structures whenever possible. This makes it super easy to work with JSON data in R, parsing the JSON but also giving back data.frames, which are easier to work with for most people. Other JSON clients in R include rjson and RJSONIO. 2.2 XML XML (Extensible Markup Language) is a markup language - not just a data interchange format as is JSON. You can find the specification at https://www.w3.org/TR/xml/. Here’s an example: &lt;foo&gt; &lt;bar&gt;Hello World!&lt;/bar&gt; &lt;/foo&gt; You can see how XML differs from JSON, but also the similarities. XML uses named elements, which JSON also uses (it’s keys). XML simply takes up more text (bytes) to transfer the same amount of content, which makes JSON more appealing in cases where efficiency matters (e.g. in browser, and mobile platforms). 2.3 HTML HTML (Hyptertext Markup Lanugage) is the language of the web (together with CSS for styling and Javascript for adding behavior). Working with HTML as a data type is a last resort option. Sometimes you need data from a website, but all they have the HTML that defines the page. This is a last resort because it can be difficult/frustrating to extract what you want from HTML. In addition, HTML that defines a page can be changed at any moment, breaking your code to work with it - whereas an API or a file you download likely will not change, or change less often, or change in non-breaking ways. The best tools in R for working with HTML include xml2 and rvest. 2.4 Files I won’t go into detail on files as there are hundreds, if not more, different file formats. Good R tools for working with files are readr, data.table::fread, rio, etc. When files are large it’s a good idea to cache them on the user’s machine so that subsequent requests for the same files only take the time to read in the file, not the downloading time. Best practice for this is the package rappdirs, which makes it easy to determine locations across operating systems for different types of file storage: caching vs. data vs. configuration vs. logging. "],
["apis.html", "3 APIs 3.1 Breakdown of the types 3.2 RPC 3.3 SOAP 3.4 REST 3.5 Others", " 3 APIs 3.1 Breakdown of the types RPC - Remote Procedure Call. Some types: XML-RPC JSON-RPC, example implementation: [js-jrpc][https://github.com/vphantom/js-jrpc] SOAP - Simple Object Access Protocol REST - Representational State Transfer Each of the above use a: Data format: e.g., JSON Transport mechanism: e.g., HTTP These attributes will be highlighted below for each API category. 3.2 RPC Data format: various, including JSON, XML Transport mechanism: various xxxx 3.3 SOAP Data format: XML Transport mechanism: HTTP, SMTP SOAP is a successor to XML-RPC, using XML for the data format. SOAP maintains state on the server The best part about SOAP is that it programatically defines the API. That is, in machine readable XML, the definition for the API - it’s routes, parameters, and allowed operations - are all defined so that machines can understand. This allows for client libraries to be created programatically. This is one of the huge downsides of REST is that they generally have no machine readable definition, such that nearly all client libraries created for REST APIs are done by hand, each one separately. At the risk of being opinionated, SOAP is a technology that’s on its way out. Especially in the R world, the SOAP client that exists (SSOAP) often doesn’t work on various R versions and platforms. And no other efforts are being made for another SOAP client. 3.4 REST Data format: various, most often JSON Transport mechanism: HTTP 3.5 Others A few others worth mentioning: GraphQL - a Facebook product. Breaks from REST by introducing the concept of defining the data you want back in your query, and the server figures out how to get you that data. Whereas with REST you’d have a mental model of what you want, and make various REST calls to get that data. GraphQL isn’t widely used, and there’s currently no GraphQL clients for R. "],
["working-with-apis.html", "4 Working with APIs 4.1 xxx", " 4 Working with APIs In this chapter we’ll 4.1 xxx "],
["api-clients.html", "5 API clients 5.1 Writing R packages 5.2 Core HTTP helpers 5.3 What to return to users 5.4 Abstracted vs. 1-to-1 user interfaces 5.5 HTTP request inspection", " 5 API clients 5.1 Writing R packages see Hadley’s book… 5.2 Core HTTP helpers 5.3 What to return to users 5.4 Abstracted vs. 1-to-1 user interfaces 5.5 HTTP request inspection "],
["curl.html", "6 curl 6.1 Discover curl options 6.2 Other ways to use curl besides R 6.3 Install httr 6.4 general option setting 6.5 curl options in rOpenSci packages 6.6 timeout 6.7 verbose 6.8 headers 6.9 authenticate 6.10 cookies 6.11 progress 6.12 proxies 6.13 user agent", " 6 curl curl is the de facto standard tool for making HTTP requests - in addition to many other types of data requests. It is also an R package (https://cran.rstudio.com/web/packages/curl/). 6.1 Discover curl options You can go to the source, that is the curl manual page at http://curl.haxx.se/docs/manpage.html. In R: RCurl::listCurlOptions() for finding curl options, give website for more info and equivalent call in httr is httr::httr_options(). httr::httr_options() gives more information for each curl option, including the libcurl variable name (e.g., CURLOPT_CERTINFO) and the type of variable (e.g., logical). 6.2 Other ways to use curl besides R Perhaps the canonical way to use curl is on the command line. You can get curl for your operating system at http://curl.haxx.se/download.html, though hopefully you already have curl. Once you have curl, you can have lots of fun. For example, get the contents of the Google landing page: curl https://www.google.com If you like that you may also like httpie, a Python command line tool that is a little more convenient than curl (e.g., JSON output is automatically parsed and colorized). Alot of data from the web is in JSON format. A great command line tool to pair with curl is jq. Note: if you are on windows you may require extra setup if you want to play with curl on the command line. OSX and linux have it by default. On Windows 8, installing the latest version from here http://curl.haxx.se/download.html#Win64 worked for me. 6.3 Install httr Note: RCurl is a dependency, so you’ll get it when you install httr install.packages(&quot;httr&quot;) There are some new features in httr dev version you may want. If so, do: install.packages(&quot;devtools&quot;) devtools::install_github(&quot;hadley/httr&quot;) Load httr library(&quot;httr&quot;) 6.4 general option setting With httr you can either set globally for an R session like set_config(timeout(seconds = 2)) Or use with_config() with_config(verbose(), { GET(&quot;http://www.google.com/search&quot;) }) Or extensions to with_*, like for verbose output with_verbose( GET(&quot;http://www.google.com/search&quot;) ) #&gt; Response [http://www.google.com/webhp] #&gt; Date: 2016-04-15 13:53 #&gt; Status: 200 #&gt; Content-Type: text/html; charset=ISO-8859-1 #&gt; Size: 10.5 kB #&gt; &lt;!doctype html&gt;&lt;html itemscope=&quot;&quot; itemtype=&quot;http://schema.org/WebPage&quot; l... #&gt; function _gjh(){!_gjuc()&amp;&amp;window.google&amp;&amp;google.x&amp;&amp;google.x({id:&quot;GJH&quot;},f... #&gt; &lt;/style&gt;&lt;style&gt;body,td,a,p,.h{font-family:arial,sans-serif}body{margin:0... #&gt; if (!iesg){document.f&amp;&amp;document.f.q.focus();document.gbqf&amp;&amp;document.gbqf... #&gt; } #&gt; })();&lt;/script&gt;&lt;div id=&quot;mngb&quot;&gt; &lt;div id=gbar&gt;&lt;nobr&gt;&lt;b class=gb1&gt;Search&lt;... Or pass into each function call GET(&quot;http://www.google.com/search&quot;, query=list(q=&quot;httr&quot;), timeout(seconds = 0.5)) With RCurl you can set options for a function call by passing curl options to the .opts parameter getForm(&quot;http://www.google.com/search?q=RCurl&quot;, btnG=&quot;Search&quot;, .opts = list(timeout.ms = 20)) For all examples below I’ll use httr, and pass in config options to function calls. 6.5 curl options in rOpenSci packages In most of our packages we allow you to pass in any curl options, either via ... or a named parameter. We are increasingly making our packages consistent, but they may not all have this ability yet. For example, using the rgbif package, an R client for GBIF: install.packages(&quot;rgbif&quot;) verbose output library(&quot;rgbif&quot;) res &lt;- occ_search(geometry=c(-125.0,38.4,-121.8,40.9), limit=20, config=verbose()) #&gt; -&gt; GET /v1/occurrence/search?geometry=POLYGON%28%28-125%2038.4%2C%20-121.8%2038.4%2C%20-121.8%2040.9%2C%20-125%2040.9%2C%20-125%2038.4%29%29&amp;limit=20&amp;offset=0 HTTP/1.1 #&gt; -&gt; User-Agent: curl/7.37.1 Rcurl/1.95.4.5 httr/0.6.0 #&gt; -&gt; Host: api.gbif.org #&gt; -&gt; Accept-Encoding: gzip #&gt; -&gt; Accept: application/json, text/xml, application/xml, */* #&gt; -&gt; #&gt; &lt;- HTTP/1.1 200 OK #&gt; &lt;- Content-Type: application/json #&gt; &lt;- Access-Control-Allow-Origin: * #&gt; &lt;- Server: Jetty(9.1.z-SNAPSHOT) #&gt; &lt;- x-api-url: /v1/occurrence/search?geometry=POLYGON%28%28-125%2038.4%2C%20-121.8%2038.4%2C%20-121.8%2040.9%2C%20-125%2040.9%2C%20-125%2038.4%29%29&amp;limit=20&amp;offset=0 #&gt; &lt;- Content-Length: 48698 #&gt; &lt;- Accept-Ranges: bytes #&gt; &lt;- Date: Tue, 16 Dec 2014 23:35:52 GMT #&gt; &lt;- X-Varnish: 1067986052 1067940827 #&gt; &lt;- Age: 209 #&gt; &lt;- Via: 1.1 varnish #&gt; &lt;- Connection: keep-alive #&gt; &lt;- Print progress res &lt;- occ_search(geometry=c(-125.0,38.4,-121.8,40.9), limit=20, config=progress()) #&gt; |===================================================================| 100% You can also combine curl options - use c() in this case to combine them c(verbose(), progress()) #&gt; &lt;request&gt; #&gt; Options: #&gt; * debugfunction: function (type, msg) #&gt; { #&gt; switch(type + 1, text = if (info) prefix_message(&quot;* &quot;, msg), headerIn = prefix_message(&quot;&lt;- &quot;, msg), headerOut = prefix_message(&quot;-&gt; &quot;, msg), dataIn = if (data_in) prefix_message(&quot;&lt;&lt; &quot;, msg, TRUE), dataOut = if (data_out) prefix_message(&quot;&gt;&gt; &quot;, msg, TRUE), sslDataIn = if (data_in &amp;&amp; ssl) prefix_message(&quot;*&lt; &quot;, msg, TRUE), sslDataOut = if (data_out &amp;&amp; ssl) prefix_message(&quot;*&gt; &quot;, msg, TRUE)) #&gt; } #&gt; * verbose: TRUE #&gt; * noprogress: FALSE #&gt; * progressfunction: function (down, up) #&gt; { #&gt; if (type == &quot;down&quot;) { #&gt; total &lt;- down[[1]] #&gt; now &lt;- down[[2]] #&gt; } #&gt; else { #&gt; total &lt;- up[[1]] #&gt; now &lt;- up[[2]] #&gt; } #&gt; if (total == 0 &amp;&amp; now == 0) { #&gt; bar &lt;&lt;- NULL #&gt; first &lt;&lt;- TRUE #&gt; return(TRUE) #&gt; } #&gt; if (total == 0) { #&gt; if (first) { #&gt; first &lt;&lt;- FALSE #&gt; } #&gt; cat(&quot;\\rDownloading: &quot;, bytes(now, digits = 2), &quot; &quot;, sep = &quot;&quot;) #&gt; if (now == total) #&gt; cat(&quot;\\n&quot;) #&gt; utils::flush.console() #&gt; } #&gt; else { #&gt; if (is.null(bar)) { #&gt; bar &lt;&lt;- utils::txtProgressBar(max = total, style = 3) #&gt; } #&gt; utils::setTxtProgressBar(bar, now) #&gt; } #&gt; TRUE #&gt; } res &lt;- occ_search(geometry=c(-125.0,38.4,-121.8,40.9), limit=20, config=c(verbose(), progress())) #&gt; -&gt; GET /v1/occurrence/search?geometry=POLYGON%28%28-125%2038.4%2C%20-121.8%2038.4%2C%20-121.8%2040.9%2C%20-125%2040.9%2C%20-125%2038.4%29%29&amp;limit=20&amp;offset=0 HTTP/1.1 #&gt; -&gt; User-Agent: curl/7.37.1 Rcurl/1.95.4.5 httr/0.6.0 #&gt; -&gt; Host: api.gbif.org #&gt; -&gt; Accept-Encoding: gzip #&gt; -&gt; Accept: application/json, text/xml, application/xml, */* #&gt; -&gt; #&gt; &lt;- HTTP/1.1 200 OK #&gt; &lt;- Content-Type: application/json #&gt; &lt;- Access-Control-Allow-Origin: * #&gt; &lt;- Server: Jetty(9.1.z-SNAPSHOT) #&gt; &lt;- x-api-url: /v1/occurrence/search?geometry=POLYGON%28%28-125%2038.4%2C%20-121.8%2038.4%2C%20-121.8%2040.9%2C%20-125%2040.9%2C%20-125%2038.4%29%29&amp;limit=20&amp;offset=0 #&gt; &lt;- Content-Length: 48698 #&gt; &lt;- Accept-Ranges: bytes #&gt; &lt;- Date: Tue, 16 Dec 2014 23:35:52 GMT #&gt; &lt;- X-Varnish: 1067986052 1067940827 #&gt; &lt;- Age: 209 #&gt; &lt;- Via: 1.1 varnish #&gt; &lt;- Connection: keep-alive #&gt; &lt;- #&gt; |======================================================================| 100% 6.6 timeout Set a timeout for a request. If request exceeds timeout, request stops. httr: timeout(seconds=2) Here, the value is in seconds - converted to ms internally RCurl: timeout.ms=2000 Here, the value is in ms Note: For this section and those following, I’ll mention an RCurl equivalent if there is one. GET(&quot;http://www.google.com/search&quot;, timeout(0.01)) #&gt; Error in function (type, msg, asError = TRUE) : #&gt; Connection timed out after 16 milliseconds Why use this? You sometimes are working with a web resource that is somewhat unreliable. For example, if you want to run a script on a server that may take many hours, and the web resource could be down at some point during that time, you could set the timeout and error catch the response so that the script doesn’t hang on a server that’s not responding. Another example could be if you call a web resource in an R package. In your test suite, you may want to test that a web resource is responding quickly, so you could set a timeout, and not test if that fails. 6.7 verbose Print detailed info on a curl call httr: verbose() RCurl: verbose=TRUE Just do a HEAD request so we don’t have to deal with big output HEAD(&quot;http://www.google.com/search&quot;, verbose()) #&gt; -&gt; HEAD / HTTP/1.1 #&gt; -&gt; User-Agent: curl/7.37.1 Rcurl/1.95.4.5 httr/0.6.0 #&gt; -&gt; Host: had.co.nz #&gt; -&gt; Accept-Encoding: gzip #&gt; -&gt; Accept: application/json, text/xml, application/xml, */* #&gt; -&gt; #&gt; &lt;- HTTP/1.1 200 OK #&gt; &lt;- X-Powered-By: PHP/4.4.6 #&gt; &lt;- Content-type: text/html #&gt; &lt;- Date: Tue, 16 Dec 2014 21:03:21 GMT #&gt; &lt;- Server: LiteSpeed #&gt; &lt;- Connection: Keep-Alive #&gt; &lt;- Keep-Alive: timeout=5, max=100 #&gt; &lt;- #&gt; Response [http://had.co.nz/] #&gt; Date: 2014-12-16 12:29 #&gt; Status: 200 #&gt; Content-Type: text/html #&gt; &lt;EMPTY BODY&gt; Why use this? As you can see verbose output gives you lots of information that may be useful for debugging a request. You typically don’t need verbose output unless you want to inspect a request. 6.8 headers Add headers to modify requests, including authentication, setting content-type, accept type, etc. httr: add_headers() RCurl: httpheader res &lt;- HEAD(&quot;http://www.google.com/search&quot;, add_headers(Accept = &quot;application/json&quot;)) res$request$opts$httpheader #&gt; NULL Note: there are shortcuts for add_headers(Accept = &quot;application/json&quot;) and add_headers(Accept = “application/xml”): accept_json(), and accept_xml() Why use this? For some web resources, using headers is mandatory, and httr makes including them quite easy. Headers are nice too because e.g., passing authentication in the header instead of the URL string means your private data is not as exposed to prying eyes. 6.9 authenticate Set authentication details for a resource httr: authenticate(), oauth2.0_token(), oauth_app(), oauth_endpoint(), etc. RCurl: various authenticate() for basic username/password authentication authenticate(user = &quot;foo&quot;, password = &quot;bar&quot;) #&gt; &lt;request&gt; #&gt; Options: #&gt; * httpauth: 1 #&gt; * userpwd: foo:bar To use an API key, this depends on the data provider. They may request it one or either of the header (in multiple different ways) HEAD(&quot;http://www.google.com/search&quot;, add_headers(Authorization = &quot;Bearer 234kqhrlj2342&quot;)) # or HEAD(&quot;http://www.google.com/search&quot;, add_headers(&quot;token&quot; = &quot;234kqhrlj2342&quot;)) or as a query parameter (which is passed in the URL string) HEAD(&quot;http://www.google.com/search&quot;, query = list(api_key = &quot;&lt;your key&gt;&quot;)) Another authentication options is OAuth workflows. OAuth2 is probably more commonly used than OAuth1. Find OAuth settings for github http://developer.github.com/v3/oauth/ endpts &lt;- oauth_endpoint(authorize = &quot;authorize&quot;, access = &quot;access_token&quot;, base_url = &quot;https://github.com/login/oauth&quot;) Register an application at https://github.com/settings/applications. Use any URL you would like for the homepage URL (http://github.com is fine) and http://localhost:1410 as the callback url. Insert your client ID and secret below - if secret is omitted, it will look it up in the GITHUB_CONSUMER_SECRET environmental variable. myapp &lt;- oauth_app(appname = &quot;github&quot;, key = &quot;&lt;key&gt;&quot;, secret = &quot;&lt;secret&gt;&quot;) Get OAuth credentials github_token &lt;- oauth2.0_token(endpts, myapp) Use API gtoken &lt;- config(token = github_token) req &lt;- GET(&quot;https://api.github.com/rate_limit&quot;, gtoken) content(req) 6.10 cookies Set or get cookies. httr: set_cookies(), cookies() RCurl: cookie Set cookies GET(&quot;http://httpbin.org/cookies&quot;, set_cookies(a = 1, b = 2)) #&gt; Response [http://httpbin.org/cookies] #&gt; Date: 2016-04-15 13:53 #&gt; Status: 200 #&gt; Content-Type: application/json #&gt; Size: 51 B #&gt; No encoding supplied: defaulting to UTF-8. #&gt; { #&gt; &quot;cookies&quot;: { #&gt; &quot;a&quot;: &quot;1&quot;, #&gt; &quot;b&quot;: &quot;2&quot; #&gt; } #&gt; } If there are cookies in a response, you can access them easily with cookies() res &lt;- GET(&quot;http://httpbin.org/cookies/set&quot;, query = list(a = 1, b = 2)) cookies(res) #&gt; domain flag path secure expiration name value #&gt; 1 httpbin.org FALSE / FALSE &lt;NA&gt; a 1 #&gt; 2 httpbin.org FALSE / FALSE &lt;NA&gt; b 2 6.11 progress Print curl progress httr: progress() RCurl: progressfunction res &lt;- GET(&quot;http://httpbin.org&quot;, progress()) #&gt; |==================================| 100% Why use this? As you could imagine, this is increasingly useful as a request for a web resource takes longer and longer. For very long requests, this will help you know approximately when a request will finish. 6.12 proxies When behind a proxy, give authentiction details for your proxy. httr: use_proxy() RCurl: See various curl options that start with proxy GET(&quot;http://www.google.com/search&quot;, use_proxy(url = &quot;125.39.66.66&quot;, port = 80, username = &quot;username&quot;, password = &quot;password&quot;)) Why use this? Most of us likely don’t need to worry about this. However, if you are in a work place, or maybe in certain geographic locations, you may have to use a proxy. I haven’t personally used a proxy in R, so any feedback on this is great. 6.13 user agent Some resources require a user-agent string. httr: user_agent() RCurl: useragent Get the default user agent set if using httr GET(&quot;http://httpbin.org/user-agent&quot;) #&gt; Response [http://httpbin.org/user-agent] #&gt; Date: 2016-04-15 13:53 #&gt; Status: 200 #&gt; Content-Type: application/json #&gt; Size: 61 B #&gt; No encoding supplied: defaulting to UTF-8. #&gt; { #&gt; &quot;user-agent&quot;: &quot;libcurl/7.43.0 r-curl/0.9.7 httr/1.1.0&quot; #&gt; } Set a user agent string GET(&quot;http://httpbin.org/user-agent&quot;, user_agent(&quot;its me!&quot;)) #&gt; Response [http://httpbin.org/user-agent] #&gt; Date: 2016-04-15 13:53 #&gt; Status: 200 #&gt; Content-Type: application/json #&gt; Size: 30 B #&gt; No encoding supplied: defaulting to UTF-8. #&gt; { #&gt; &quot;user-agent&quot;: &quot;its me!&quot; #&gt; } Why use this? This is set by default in a http request, as you can see in the first example above for user agent. Some web APIs require that you set a specific user agent. For example, the GitHub API requires that you include a user agent string in the header of each request that is your username or the name of your application so they can contact you if there is a problem. "],
["ftp.html", "7 FTP", " 7 FTP File Transfer Protocol, or FTP, is a standard network protocol for transfering files between a client and server. In practice, using FTP is just like grabbing some files off someone else’s computer file system. "],
["http.html", "8 HTTP 8.1 HTTP/2", " 8 HTTP Hypertext Transer Protocol, or HTTP, is an application protocol for data transfer, and is the foundation of data communication for the World Wide Web. 8.1 HTTP/2 HTTP/2 (see also https://http2.github.io/) is the next iteration of the HTTP protocol. It is born out of the standard created by Google called SPDY. In practice, HTTP/2 likely won’t be widely used for a few years. As of June 2016, HTTP/2 was used by 8.2% of all websites. "],
["caching.html", "9 Caching 9.1 Why cache? 9.2 http based caching 9.3 R based caching", " 9 Caching 9.1 Why cache? 9.2 http based caching e-tag cache control 9.3 R based caching 9.3.1 vcr 9.3.2 rappdirs 9.3.3 other packages There are many others not specifically for caching, but you can use them for caching: asdf adsf asdf "],
["packaging.html", "10 Packaging 10.1 HTTP functions 10.2 Curl options", " 10 Packaging Hadley Wickham’s book R Package Development (ref) covers R package development in detail - thus, I will focus in this chapter on those aspects of package development that are most relavant to developing packages for consuming web resources. 10.1 HTTP functions You’ll likely need to use the same or similar code to request web resources. Therefore, it usually makes sense to have a file with these internal functions, and then reuse them wherever needed. This way, when changes are needed for internal HTTP functions you can make changes in one place. This is essentially the same as saying Don’t Repeat Yourself (DRY). A good way to write internal HTTP functions for a web resource is as follows: First, define a generic function that can be used for any HTTP verb: my_VERB &lt;- function(verb, url, ...) { url &lt;- as.url(url) VERB &lt;- getExportedValue(&quot;httr&quot;, verb) res &lt;- VERB(url, ..., do_oauth()) # No content if (length(res$content) == 0) { httr::stop_for_status(res) return(invisible(TRUE)) } text &lt;- httr::content(res, as = &quot;text&quot;, encoding = &quot;UTF-8&quot;) json &lt;- jsonlite::fromJSON(text, simplifyVector = FALSE) if (httr::status_code(res) &gt;= 400) { stop(json$message, call. = FALSE) } json } Then, define functions for each of the HTTP verbs you need: GET do_GET &lt;- function(url, ...) { my_VERB(&quot;GET&quot;, url, ...) } POST do_POST &lt;- function(url, ..., body = NULL, encode = &quot;json&quot;) { body &lt;- ascompact(body) my_VERB(&quot;POST&quot;, url, ..., body = body, encode = encode) } PUT do_PUT &lt;- function(url, ...) { my_VERB(&quot;PUT&quot;, url, ...) } DELETE do_DELETE &lt;- function(url, ...) { my_VERB(&quot;DELETE&quot;, url, ...) } 10.2 Curl options It’s best practice to always allow users to pass in curl options. Many users will never need these, but power users that are familiar with curl will appreciate the option. In addition, there are a number of situations that will make you glad you built it in. When users of your package are at a workplace, they can sometimes be blocked from accessing the resources your package works with - either because some ports are blocked, or otehr reasons. If they can pass in curl options they can often get around these issues. Curl options also allow users to pass in headers, which are important in many situations. "],
["testing.html", "11 Testing 11.1 testthat 11.2 Mocking web requests 11.3 webmockr", " 11 Testing 11.1 testthat 11.1.1 Skipping tests You should skip any tests on CRAN via testthat::skip_on_cran() that call web resources, whether they be an API, FTP, flat file, or URL. This is because those web resources can be down when the test is run - at which point CRAN maintainers will complain to you that your tests are failing. There are likely a subset of unit tests you can run for functions that call web resources - e.g., you can test failure modes if the function call does not actually make a web request, but rather is testing parameter inputs, etc. If you skip tests on CRAN, you should still run tests on your continuous integration system. But those can be skipped as well via testthat::skip_on_travis(). 11.1.2 Test if web resource is up One approach to web resources is to safely test if the web service is up or not before running further tests. This way you can still run your test suite if the web resourcs is up, but avoid failures if it is not up. 11.2 Mocking web requests A commonly used solution in test suites in other programming languages is to mock web requests. That is, you can store the results of a web request (usually as JSON data) in files in your test suite directory, then test expections use those cached files instead of doing real web requests. This requires that web requests are matched against the available cached files. This approach of course requires libraries that provide the infrastructure to do make this easy - two approaches are described below with two R packages ported from the Ruby programming language. 11.2.1 vcr vcr takes the approach of storing cached requests in specifically named files, or cassettes. You insert a cassette to use it, do web requests, then eject the cassette when done. After ejection, the file is still there, but you are no longer writing to it. Note: It is still in early development, so expect changes. 11.3 webmockr webmockr takes a different approach than vcr. It doesn’t require you to set up certain files to write to, but rather caches responses to web requests in the Ruby session during interactive use. Of course, for usage in a test suite, the responses are written to files, that then are used in subsequent test suite runs. "],
["package-automation.html", "12 Package Automation 12.1 API Specifications 12.2 Package generator 12.3 Keeping up to date", " 12 Package Automation Writing bespoke R clients can be lots of fun, and is often necessary beacuse any two randomly chosen REST APIs do not use the same patterns. However, there are some ways to automate package creation. 12.1 API Specifications Some REST APIs have machine readable specifications for their API. Most small operations don’t have time for this, so you usually see this in larger companies. These specifications allow a definition of the API, but can also be used to programmatically create a client. The apispecs repo https://github.com/ropenscilabs/apispecs holds an increasing set of API specifications targeting smaller scientifically useful APIs that don’t already have specifications. We are using the OpenAPI specification. xxx… 12.2 Package generator apipkgen https://github.com/ropenscilabs/apipkgen is a package that can be used to generate R clients from API specs. The following is a brief example devtools::install_github(&quot;ropenscilabs/apipkgen&quot;) library(&quot;apipkgen&quot;) Generate a package using the function generate_pkg() template &lt;- system.file(&#39;examples&#39;, &#39;template_crossref.yml&#39;, package = &quot;apipkgen&quot;) apipkgen::generate_pkg(&quot;../crpkg&quot;, template_path = template) The package created doesn’t have any exported functions, just internal functions for your to build user facing functions. Let’s write a user facing functions. The Crossref API template above specified for the works route that parameters are query and rows. So let’s work with those. crossref_works &lt;- function(query = NULL, rows = NULL, ...) { works(query = query, rows = rows, ...) } In addition, it’s a good idea to always allow users to pass in curl options. Beginners can ignore it, but power curl users will want/have to play with curl options. The function builder builds in ... as a parameter so in the user facing function above all you have to do is add that as well for users to access. Now install the new package. Go to the new directory, and in R/RStudio run devtools::document() and devtools::install() (or equivalent). Now you can use the package. Call the function. The package builder gives back plain text, so you have to parse it yourself. res &lt;- crossref_works(query = &quot;science&quot;) jsonlite::fromJSON(res) #&gt; $status #&gt; [1] &quot;ok&quot; #&gt; #&gt; $`message-type` #&gt; [1] &quot;work-list&quot; #&gt; #&gt; $`message-version` #&gt; [1] &quot;1.0.0&quot; #&gt; #&gt; $message #&gt; $message$query #&gt; $message$query$`search-terms` #&gt; [1] &quot;science&quot; #&gt; #&gt; $message$query$`start-index` #&gt; [1] 0 #&gt; #&gt; #&gt; $message$`items-per-page` #&gt; [1] 20 #&gt; #&gt; $message$items #&gt; indexed.date-parts indexed.date-time indexed.timestamp reference-count #&gt; 1 2015, 12, 27 2015-12-27T23:37:50Z 1.451259e+12 0 #&gt; 2 2015, 12, 24 2015-12-24T22:03:23Z 1.450995e+12 0 #&gt; 3 2015, 12, 25 2015-12-25T19:17:30Z 1.451071e+12 0 #&gt; 4 2015, 12, 27 2015-12-27T19:35:51Z 1.451245e+12 0 12.3 Keeping up to date xxxx "]
]
